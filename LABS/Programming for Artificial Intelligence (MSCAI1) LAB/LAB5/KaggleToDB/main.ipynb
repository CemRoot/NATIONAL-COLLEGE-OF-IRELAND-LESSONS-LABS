{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the datasets (You should replace these with the actual paths to your files)\n",
    "df_part1 = pd.read_csv('archive/item_properties_part1.csv')\n",
    "df_part2 = pd.read_csv('archive/item_properties_part2.csv')\n",
    "\n",
    "# Combine both parts of item properties\n",
    "df_properties = pd.concat([df_part1, df_part2])"
   ],
   "id": "a8a1adac2cd208dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Explore available properties\n",
    "unique_properties = df_properties['property'].unique()\n",
    "print(\"Unique properties:\", unique_properties)"
   ],
   "id": "9e7bd7f3da6a3ba5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract rows where the value looks like a number (e.g., price)\n",
    "df_numeric_properties = df_properties[df_properties['value'].str.startswith('n', na=False)]\n",
    "\n",
    "# Check how many unique item ids have numerical values\n",
    "print(df_numeric_properties[['itemid', 'property', 'value']].drop_duplicates().head(10))\n",
    "\n",
    "# Look for potential price columns by observing the value patterns\n",
    "# If necessary, filter for potential \"price\" properties by looking at large numbers.\n"
   ],
   "id": "df33a5d6a964f77c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Extract rows where property might represent availability or stock (likely binary)\n",
    "df_stock_properties = df_properties[df_properties['property'] == 'available']\n",
    "\n",
    "# Check the values\n",
    "print(df_stock_properties[['itemid', 'value']].drop_duplicates().head(10))\n"
   ],
   "id": "fadef80cfec116da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pivot the data using identified properties\n",
    "df_pivot = df_properties.pivot_table(index='itemid', columns='property', values='value', aggfunc='first').reset_index()\n",
    "\n",
    "# Example: If we know '888' is price and 'available' is stock\n",
    "df_pivot.rename(columns={\n",
    "    '888': 'price',  # Hypothetical mapping\n",
    "    'available': 'stock',  # Stock column\n",
    "    'categoryid': 'category'\n",
    "}, inplace=True)\n",
    "\n",
    "# Fill missing values\n",
    "df_pivot['price'] = df_pivot['price'].fillna(0).astype(float)  # Default price to 0.0\n",
    "df_pivot['stock'] = df_pivot['stock'].fillna(1).astype(int)  # Default stock to 1 (available)\n",
    "\n",
    "# Assuming 'itemid' acts as product_id\n",
    "df_products = df_pivot[['itemid', 'price', 'stock', 'category']]\n",
    "df_products.rename(columns={'itemid': 'product_id'}, inplace=True)\n",
    "\n",
    "# Save the cleaned product dataset for MySQL import\n",
    "df_products.to_csv('products_clean.csv', index=False)\n"
   ],
   "id": "e12f17374455a944",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '172646 1154859'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[34], line 12\u001B[0m\n\u001B[0;32m      5\u001B[0m df_pivot\u001B[38;5;241m.\u001B[39mrename(columns\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m      6\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m888\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprice\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Hypothetical mapping\u001B[39;00m\n\u001B[0;32m      7\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mavailable\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstock\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# Stock column\u001B[39;00m\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategoryid\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcategory\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      9\u001B[0m }, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# Fill missing values\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m df_pivot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprice\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf_pivot\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mprice\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfillna\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Default price to 0.0\u001B[39;00m\n\u001B[0;32m     13\u001B[0m df_pivot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstock\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_pivot[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstock\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mfillna(\u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)  \u001B[38;5;66;03m# Default stock to 1 (available)\u001B[39;00m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;66;03m# Assuming 'itemid' acts as product_id\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:6643\u001B[0m, in \u001B[0;36mNDFrame.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m   6637\u001B[0m     results \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m   6638\u001B[0m         ser\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy, errors\u001B[38;5;241m=\u001B[39merrors) \u001B[38;5;28;01mfor\u001B[39;00m _, ser \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m   6639\u001B[0m     ]\n\u001B[0;32m   6641\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   6642\u001B[0m     \u001B[38;5;66;03m# else, only a single dtype is given\u001B[39;00m\n\u001B[1;32m-> 6643\u001B[0m     new_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_mgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   6644\u001B[0m     res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_constructor_from_mgr(new_data, axes\u001B[38;5;241m=\u001B[39mnew_data\u001B[38;5;241m.\u001B[39maxes)\n\u001B[0;32m   6645\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mastype\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001B[0m, in \u001B[0;36mBaseBlockManager.astype\u001B[1;34m(self, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    427\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m using_copy_on_write():\n\u001B[0;32m    428\u001B[0m     copy \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m--> 430\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    431\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mastype\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    432\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    433\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    434\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    435\u001B[0m \u001B[43m    \u001B[49m\u001B[43musing_cow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43musing_copy_on_write\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    436\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001B[0m, in \u001B[0;36mBaseBlockManager.apply\u001B[1;34m(self, f, align_keys, **kwargs)\u001B[0m\n\u001B[0;32m    361\u001B[0m         applied \u001B[38;5;241m=\u001B[39m b\u001B[38;5;241m.\u001B[39mapply(f, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    362\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 363\u001B[0m         applied \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mgetattr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    364\u001B[0m     result_blocks \u001B[38;5;241m=\u001B[39m extend_blocks(applied, result_blocks)\n\u001B[0;32m    366\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39mfrom_blocks(result_blocks, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maxes)\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:758\u001B[0m, in \u001B[0;36mBlock.astype\u001B[1;34m(self, dtype, copy, errors, using_cow, squeeze)\u001B[0m\n\u001B[0;32m    755\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCan not squeeze with more than one column.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    756\u001B[0m     values \u001B[38;5;241m=\u001B[39m values[\u001B[38;5;241m0\u001B[39m, :]  \u001B[38;5;66;03m# type: ignore[call-overload]\u001B[39;00m\n\u001B[1;32m--> 758\u001B[0m new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array_safe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    760\u001B[0m new_values \u001B[38;5;241m=\u001B[39m maybe_coerce_values(new_values)\n\u001B[0;32m    762\u001B[0m refs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001B[0m, in \u001B[0;36mastype_array_safe\u001B[1;34m(values, dtype, copy, errors)\u001B[0m\n\u001B[0;32m    234\u001B[0m     dtype \u001B[38;5;241m=\u001B[39m dtype\u001B[38;5;241m.\u001B[39mnumpy_dtype\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 237\u001B[0m     new_values \u001B[38;5;241m=\u001B[39m \u001B[43mastype_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    238\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[0;32m    239\u001B[0m     \u001B[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001B[39;00m\n\u001B[0;32m    240\u001B[0m     \u001B[38;5;66;03m#  trying to convert to float\u001B[39;00m\n\u001B[0;32m    241\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001B[0m, in \u001B[0;36mastype_array\u001B[1;34m(values, dtype, copy)\u001B[0m\n\u001B[0;32m    179\u001B[0m     values \u001B[38;5;241m=\u001B[39m values\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[0;32m    181\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 182\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[43m_astype_nansafe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    184\u001B[0m \u001B[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001B[39;00m\n\u001B[0;32m    185\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dtype, np\u001B[38;5;241m.\u001B[39mdtype) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28missubclass\u001B[39m(values\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mtype, \u001B[38;5;28mstr\u001B[39m):\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001B[0m, in \u001B[0;36m_astype_nansafe\u001B[1;34m(arr, dtype, copy, skipna)\u001B[0m\n\u001B[0;32m    129\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(msg)\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m copy \u001B[38;5;129;01mor\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m dtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mobject\u001B[39m:\n\u001B[0;32m    132\u001B[0m     \u001B[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001B[39;00m\n\u001B[1;32m--> 133\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43marr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mastype\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m arr\u001B[38;5;241m.\u001B[39mastype(dtype, copy\u001B[38;5;241m=\u001B[39mcopy)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: '172646 1154859'"
     ]
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# From this, identify columns related to 'name', 'price', 'stock', and 'description'\n",
    "# We'll extract the most recent value for each property based on the timestamp\n",
    "df_properties.sort_values(by=['itemid', 'timestamp'], ascending=[True, False], inplace=True)"
   ],
   "id": "f29207e90f59269c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Pivot the data so that each item has its properties as columns\n",
    "df_pivot = df_properties.pivot_table(index='itemid', columns='property', values='value', aggfunc='first').reset_index()"
   ],
   "id": "9fa8339f04027e5e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Select relevant columns (assuming 'name', 'price', and 'stock' are part of the available properties)\n",
    "# If the properties are not explicitly named, we may have to use placeholders or infer from other details.\n",
    "df_products = df_pivot[['itemid', 'name', 'description', 'price', 'stock']]"
   ],
   "id": "49304a63c7550dc8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Fill missing values\n",
    "df_products['description'].fillna('No description available', inplace=True)\n",
    "df_products['price'].fillna(0.0, inplace=True)  # Default price is 0.0 if missing\n",
    "df_products['stock'].fillna(100, inplace=True)  # Default stock level is 100 if missing"
   ],
   "id": "23c5482152a94c79",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
